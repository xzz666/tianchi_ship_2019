{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.read_hdf('C:/Users/f3107/Desktop/hy_data/train_204.h5')\n",
    "test_label = pd.read_hdf('C:/Users/f3107/Desktop/hy_data/test_204.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LabelEncoder\n",
    "type_map = dict(zip(train_label['type'].unique(), np.arange(3)))\n",
    "type_map_rev = {v:k for k,v in type_map.items()}\n",
    "train_label['type'] = train_label['type'].map(type_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in train_label.columns if x not in ['ship','x','y','v','d','datetime','type','t','d_d','d_t',\n",
    "                                                        'd_x','v_x','d_y','v_y','hour','date','diff_time']]\n",
    "target = 'type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_bayesian(    \n",
    "    eta,\n",
    "    max_depth,\n",
    "    n_estimators\n",
    "    ):\n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. So we make them integer\n",
    "    n_estimators = int(n_estimators)\n",
    "    max_depth = int(max_depth)\n",
    "\n",
    "    assert type(n_estimators) == int\n",
    "    assert type(max_depth) == int\n",
    "\n",
    "    params = {\n",
    "        \n",
    "        'eta':eta,\n",
    "        'booster': 'gbtree',\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class': 3,\n",
    "        'max_depth': max_depth,\n",
    "        'early_stopping_rounds': 100,\n",
    "        'n_estimators':n_estimators\n",
    "\n",
    "    }    \n",
    "\n",
    "    fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    X = train_label[features].copy()\n",
    "    y = train_label[target]\n",
    "    score = []\n",
    "\n",
    "    for index, (train_idx, val_idx) in enumerate(fold.split(X, y)):\n",
    "\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "\n",
    "        xgb_train = xgb.DMatrix(X_train, y_train)\n",
    "        xgb_eval = xgb.DMatrix(X_val, y_val)\n",
    "\n",
    "        model = xgb.train(params, xgb_train, evals=[(xgb_train, 'train'), (xgb_eval, 'val')], verbose_eval=False)\n",
    "\n",
    "        val_pred = model.predict(xgb.DMatrix(X_val))\n",
    "\n",
    "        val_y = y.iloc[val_idx]\n",
    "        f1 = metrics.f1_score(val_y, val_pred, average='macro')\n",
    "\n",
    "        score.append(f1)\n",
    "    \n",
    "    return sum(score)/len(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_LGB = {\n",
    "    \n",
    "    'eta': (0.3, 0.45),#[default = 0.3]\n",
    "    'max_depth':(40,100), #[default=6]\n",
    "    'n_estimators': (1,2000)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "LGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB, random_state=6)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    eta    | max_depth | n_esti... |\n",
      "-------------------------------------------------------------\n",
      "|  1        |  0.8851   |  0.4339   |  59.92    |  1.643e+0 |\n",
      "|  2        |  0.883    |  0.3063   |  46.46    |  1.191e+0 |\n",
      "|  3        |  0.8813   |  0.3795   |  65.13    |  671.5    |\n",
      "|  4        |  0.8829   |  0.3934   |  66.29    |  1.472e+0 |\n",
      "|  5        |  0.883    |  0.3777   |  74.73    |  1.291e+0 |\n",
      "|  6        |  0.8826   |  0.3385   |  99.02    |  1.999e+0 |\n",
      "|  7        |  0.8845   |  0.3846   |  40.53    |  2e+03    |\n",
      "|  8        |  0.8822   |  0.3879   |  40.5     |  1.998e+0 |\n",
      "|  9        |  0.881    |  0.3364   |  99.91    |  2e+03    |\n",
      "|  10       |  0.8803   |  0.4079   |  40.29    |  2.872    |\n",
      "|  11       |  0.8836   |  0.4436   |  40.08    |  1.999e+0 |\n",
      "|  12       |  0.8841   |  0.3728   |  40.16    |  1.996e+0 |\n",
      "|  13       |  0.8837   |  0.3055   |  40.38    |  1.998e+0 |\n",
      "|  14       |  0.887    |  0.4256   |  40.25    |  2e+03    |\n",
      "|  15       |  0.8811   |  0.3182   |  40.06    |  1.998e+0 |\n",
      "|  16       |  0.8798   |  0.3      |  40.04    |  1.999e+0 |\n",
      "|  17       |  0.8845   |  0.441    |  40.28    |  1.999e+0 |\n",
      "|  18       |  0.8824   |  0.3311   |  40.04    |  1.996e+0 |\n",
      "|  19       |  0.8828   |  0.3958   |  99.84    |  2e+03    |\n",
      "|  20       |  0.8862   |  0.4472   |  40.04    |  2e+03    |\n",
      "|  21       |  0.8839   |  0.3678   |  40.21    |  2e+03    |\n",
      "|  22       |  0.881    |  0.302    |  40.15    |  1.998e+0 |\n",
      "|  23       |  0.8818   |  0.3272   |  40.1     |  1.998e+0 |\n",
      "|  24       |  0.886    |  0.4443   |  40.19    |  2e+03    |\n",
      "|  25       |  0.8822   |  0.3977   |  40.23    |  1.996e+0 |\n",
      "|  26       |  0.8816   |  0.4054   |  40.01    |  1.999e+0 |\n",
      "|  27       |  0.8846   |  0.3516   |  99.62    |  1.996e+0 |\n",
      "|  28       |  0.8829   |  0.4071   |  99.7     |  1.999e+0 |\n",
      "|  29       |  0.8851   |  0.445    |  99.88    |  1.998e+0 |\n",
      "|  30       |  0.8843   |  0.4431   |  99.86    |  2e+03    |\n",
      "=============================================================\n"
     ]
    }
   ],
   "source": [
    "LGB_BO.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 25, 'ucb', 2.576, 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(LGB_BO.maximize.__defaults__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8869846185695899"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGB_BO.max['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta': 0.42563552598003573,\n",
       " 'max_depth': 40.245863353591176,\n",
       " 'n_estimators': 1999.5103231174214}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGB_BO.max['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.8888253675125923\n",
    "\n",
    "{'eta': 0.38689139253372246,\n",
    " 'max_depth': 69.90202031263354,\n",
    " 'n_estimators': 1017.6257117512797}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
