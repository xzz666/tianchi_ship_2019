{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.read_hdf('C:/Users/f3107/Desktop/hy_data/train_204.h5')\n",
    "test_label = pd.read_hdf('C:/Users/f3107/Desktop/hy_data/test_204.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LabelEncoder\n",
    "type_map = dict(zip(train_label['type'].unique(), np.arange(3)))\n",
    "type_map_rev = {v:k for k,v in type_map.items()}\n",
    "train_label['type'] = train_label['type'].map(type_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x for x in train_label.columns if x not in ['ship','x','y','v','d','datetime','type','t','d_d','d_t',\n",
    "                                                        'd_x','v_x','d_y','v_y','hour','date','diff_time']]\n",
    "target = 'type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_bayesian(\n",
    "    learning_rate,\n",
    "    num_leaves,  # int\n",
    "    max_depth,   \n",
    "    min_data_in_leaf,  # int    \n",
    "    min_sum_hessian_in_leaf,    # int      \n",
    "    feature_fraction,    \n",
    "    min_gain_to_split\n",
    "    ):\n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. So we make them integer\n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "\n",
    "    assert type(num_leaves) == int\n",
    "    assert type(min_data_in_leaf) == int\n",
    "    assert type(max_depth) == int\n",
    "\n",
    "    param = {\n",
    "        \n",
    "        'n_estimators': 5000,\n",
    "        \n",
    "        'objective': 'multiclass',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'metric': 'multi_logloss',\n",
    "        'num_class': 3,\n",
    "        \n",
    "        'learning_rate': learning_rate,      \n",
    "        'num_leaves': num_leaves,        \n",
    "        'max_depth': max_depth,\n",
    "        \n",
    "        'min_data_in_leaf': min_data_in_leaf,\n",
    "        'min_sum_hessian_in_leaf': min_sum_hessian_in_leaf,\n",
    "        \n",
    "        'bagging_fraction': 1.0,\n",
    "        'bagging_freq': 5,\n",
    "        'feature_fraction': feature_fraction,\n",
    "        'min_gain_to_split': min_gain_to_split,\n",
    "\n",
    "        'save_binary': True, \n",
    "\n",
    "        #'is_unbalance': True\n",
    "\n",
    "    }    \n",
    "\n",
    "    fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    X = train_label[features].copy()\n",
    "    y = train_label[target]\n",
    "    score = []\n",
    "\n",
    "    for index, (train_idx, val_idx) in enumerate(fold.split(X, y)):\n",
    "\n",
    "        train_set = lgb.Dataset(X.iloc[train_idx], y.iloc[train_idx])\n",
    "        val_set = lgb.Dataset(X.iloc[val_idx], y.iloc[val_idx])\n",
    "\n",
    "        model = lgb.train(param, train_set, valid_sets=[train_set, val_set], verbose_eval=False, early_stopping_rounds = 100)\n",
    "\n",
    "        val_pred = model.predict(X.iloc[val_idx])\n",
    "\n",
    "        val_y = y.iloc[val_idx]\n",
    "        val_pred = np.argmax(val_pred, axis=1)\n",
    "        f1 = metrics.f1_score(val_y, val_pred, average='macro')\n",
    "\n",
    "        score.append(f1)\n",
    "    \n",
    "    return sum(score)/len(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds_LGB = {\n",
    "    \n",
    "    'learning_rate': (0.01, 0.3), #学习率。默认为 0.1\n",
    "    'num_leaves': (5, 60),  #给出了一棵树上的叶子数。默认为 31\n",
    "    'max_depth':(5,35), #限制了树模型的最大深度，默认值为-1\n",
    "    \n",
    "    'min_data_in_leaf': (5, 20), #每个叶节点的最少样本数量。它是处理leaf-wise 树的过拟合的重要参数。\n",
    "                                 #将它设为较大的值，可以避免生成一个过深的树。但是也可能导致欠拟合。\n",
    "\n",
    "    'min_sum_hessian_in_leaf': (0.00001, 0.01), # 一个浮点数，表示一个叶子节点上的最小hessian 之和。\n",
    "                                                #（也就是叶节点样本权重之和的最小值） 默认为1e-3 。\n",
    "    \n",
    "    'feature_fraction': (0.5, 1), #来使用特征子抽样,取值范围为[0.0,1.0]， 默认值为1.0\n",
    "    \n",
    "    'min_gain_to_split': (0, 1.0) #表示执行切分的最小增益，默认为0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "LGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB, random_state=6)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | featur... | learni... | max_depth | min_da... | min_ga... | min_su... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "|  1        |  0.8917   |  0.9464   |  0.1063   |  29.64    |  5.625    |  0.1077   |  0.005955 |  34.14    |\n",
      "|  2        |  0.8791   |  0.7094   |  0.1073   |  23.68    |  11.57    |  0.7359   |  0.005185 |  36.84    |\n",
      "|  3        |  0.8507   |  0.8227   |  0.2972   |  29.6     |  11.2     |  0.8763   |  0.008239 |  7.996    |\n",
      "|  4        |  0.879    |  0.8593   |  0.2426   |  27.09    |  15.64    |  0.5409   |  0.001257 |  57.67    |\n",
      "|  5        |  0.8873   |  0.7016   |  0.07292  |  26.52    |  19.91    |  0.2556   |  0.006716 |  37.95    |\n",
      "|  6        |  0.8758   |  0.6283   |  0.2952   |  34.99    |  13.16    |  0.9723   |  0.00131  |  44.44    |\n",
      "|  7        |  0.8839   |  1.0      |  0.01     |  5.0      |  20.0     |  0.0      |  0.01     |  60.0     |\n",
      "|  8        |  0.8686   |  1.0      |  0.01     |  5.0      |  20.0     |  0.0      |  1e-05    |  5.0      |\n",
      "|  9        |  0.8904   |  0.5      |  0.01     |  5.0      |  5.0      |  2.079e-1 |  1e-05    |  13.95    |\n",
      "|  10       |  0.8901   |  0.8583   |  0.05709  |  5.73     |  5.322    |  0.005555 |  0.002248 |  59.93    |\n",
      "|  11       |  0.8852   |  0.9378   |  0.2621   |  5.018    |  5.386    |  0.02722  |  0.004106 |  41.45    |\n",
      "|  12       |  0.8925   |  0.5939   |  0.1193   |  33.62    |  5.226    |  0.1487   |  0.003445 |  59.67    |\n",
      "|  13       |  0.8967   |  0.6006   |  0.04511  |  26.77    |  5.172    |  0.007365 |  0.00348  |  50.94    |\n",
      "|  14       |  0.8912   |  0.5385   |  0.1483   |  22.75    |  5.162    |  0.01342  |  0.009203 |  59.88    |\n",
      "|  15       |  0.8937   |  0.9734   |  0.04144  |  34.4     |  5.043    |  0.0186   |  0.006847 |  49.77    |\n",
      "|  16       |  0.8921   |  0.8568   |  0.04463  |  34.56    |  19.47    |  0.02376  |  0.004249 |  58.79    |\n",
      "|  17       |  0.889    |  0.511    |  0.2896   |  33.31    |  5.306    |  0.01379  |  0.00521  |  38.7     |\n",
      "|  18       |  0.8938   |  0.9697   |  0.06762  |  16.87    |  5.286    |  0.03379  |  0.005626 |  23.99    |\n",
      "|  19       |  0.8977   |  0.8252   |  0.01079  |  20.63    |  5.138    |  0.04303  |  0.002474 |  42.42    |\n",
      "|  20       |  0.8867   |  0.9035   |  0.1362   |  8.235    |  5.215    |  0.004855 |  0.000777 |  5.088    |\n",
      "|  21       |  0.899    |  0.6786   |  0.01938  |  24.98    |  5.023    |  0.05071  |  0.005379 |  44.85    |\n",
      "|  22       |  0.8967   |  0.6047   |  0.01502  |  22.51    |  5.135    |  0.01522  |  0.008564 |  38.2     |\n",
      "|  23       |  0.8942   |  0.9647   |  0.01784  |  25.78    |  5.131    |  0.005834 |  0.004205 |  38.69    |\n",
      "|  24       |  0.8968   |  0.6249   |  0.01541  |  17.76    |  5.236    |  0.01664  |  0.005722 |  50.82    |\n",
      "|  25       |  0.8975   |  0.939    |  0.01817  |  20.06    |  5.056    |  0.03423  |  0.004969 |  41.64    |\n",
      "|  26       |  0.895    |  0.9971   |  0.08592  |  23.47    |  5.204    |  0.009244 |  0.002266 |  49.69    |\n",
      "|  27       |  0.8977   |  0.6136   |  0.01794  |  14.04    |  5.175    |  0.02228  |  0.001096 |  28.94    |\n",
      "|  28       |  0.8964   |  0.7148   |  0.02225  |  18.38    |  5.006    |  0.08728  |  0.000663 |  46.25    |\n",
      "|  29       |  0.8966   |  0.5636   |  0.01208  |  26.73    |  5.008    |  0.02664  |  0.009547 |  46.28    |\n",
      "|  30       |  0.8928   |  0.5187   |  0.02919  |  23.19    |  5.347    |  0.000128 |  0.005638 |  29.17    |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "LGB_BO.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8989593950022489"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGB_BO.max['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_fraction': 0.6785634376053006,\n",
       " 'learning_rate': 0.019383601030181666,\n",
       " 'max_depth': 24.978386879068395,\n",
       " 'min_data_in_leaf': 5.023455898071062,\n",
       " 'min_gain_to_split': 0.05071488519451617,\n",
       " 'min_sum_hessian_in_leaf': 0.005378853072855871,\n",
       " 'num_leaves': 44.84874398334702}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LGB_BO.max['params']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
