{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime as dt\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_hdf('C:/Users/f3107/Desktop/hy_data/train_002.h5')\n",
    "train['t'] = train['t'].dt.total_seconds().astype('int')\n",
    "\n",
    "test = pd.read_hdf('C:/Users/f3107/Desktop/hy_data/test_002.h5')\n",
    "test['t'] = test['t'].dt.total_seconds().astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train.drop_duplicates('ship').loc[:,['ship','type']]\n",
    "test_label = test.drop_duplicates('ship').loc[:,'ship']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异常值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 单行异常值剔除"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### v>20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['v']<20]\n",
    "test = test[test['v']<20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### xy异常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_xy(df):\n",
    "    \n",
    "    # 生成时间间隔 d_t\n",
    "    df['d_t'] = df['t'].diff()\n",
    "    df.loc[0,'d_t'] = 0\n",
    "    df['d_t'] = df['d_t'].astype('int')\n",
    "\n",
    "    # 生成d_x, d_y\n",
    "    df['d_x'] = df['x'].diff()\n",
    "    df.loc[0,'d_x'] = 0\n",
    "    df['v_x'] = df['d_x']/df['d_t']\n",
    "    df.loc[0,'v_x'] = 0\n",
    "\n",
    "    df['d_y'] = df['y'].diff()\n",
    "    df.loc[0,'d_y'] = 0\n",
    "    df['v_y'] = df['d_y']/df['d_t']\n",
    "    df.loc[0,'v_y'] = 0\n",
    "    \n",
    "    df = df[(abs(df['d_x'])<200000) & (abs(df['d_y'])<200000)]\n",
    "    df = df[(abs(df['v_x'])<15) & (abs(df['v_y'])<15)]\n",
    "    df = df[~((abs(df['v_x'])>10) & (df['v']<3)) | ((abs(df['v_y'])>10) & (df['v']<3))]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = del_xy(train)\n",
    "train = del_xy(train)\n",
    "test = del_xy(test)\n",
    "test = del_xy(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 整体异常值/停泊状态优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 整体v，d归零"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_range(train):\n",
    "\n",
    "    train_x = train['x'].groupby(train['ship']).agg(['max','min']).reset_index().rename(columns = {'max':'x_max','min':'x_min'})\n",
    "    train_y = train['y'].groupby(train['ship']).agg(['max','min']).reset_index().rename(columns = {'max':'y_max','min':'y_min'})\n",
    "    train_x['x_max_x_min'] = train_x['x_max'] - train_x['x_min']\n",
    "    train_y['y_max_y_min'] = train_y['y_max'] - train_y['y_min']\n",
    "\n",
    "    train_data = pd.merge(train_x, train_y, on ='ship')\n",
    "\n",
    "    ship_ID = list(train_data['ship'][(train_data['x_max_x_min']<100)&(train_data['y_max_y_min']<100)])\n",
    "\n",
    "    return ship_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_ID = xy_range(train)\n",
    "train['v'][train.ship.isin(ship_ID)] = 0\n",
    "train['d'][train.ship.isin(ship_ID)] = 0\n",
    "\n",
    "ship_ID = xy_range(test)\n",
    "test['v'][test.ship.isin(ship_ID)] = 0\n",
    "test['d'][test.ship.isin(ship_ID)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 统计特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 时间特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dt(df):\n",
    "\n",
    "    df['day'] = df['datetime'].dt.day\n",
    "    df['weekday'] = df['datetime'].dt.weekday\n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = extract_dt(train)\n",
    "test = extract_dt(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max, min, mean, std, skew, sum, max-min, slope, area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_feature(df, key, target, aggs):   \n",
    "    agg_dict = {}\n",
    "    for ag in aggs:\n",
    "        agg_dict[f'{target}_{ag}'] = ag\n",
    "    #print(agg_dict)\n",
    "    t = df.groupby(key)[target].agg(agg_dict).reset_index()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(df, train):\n",
    "    \n",
    "    t = group_feature(df, 'ship','x',['max','min','mean','std','skew','sum']) \n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    t = group_feature(df, 'ship','y',['max','min','mean','std','skew','sum'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    t = group_feature(df, 'ship','v',['max','min','mean','std','skew','sum'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    t = group_feature(df, 'ship','d',['max','min','mean','std','skew','sum'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "\n",
    "    '''\n",
    "    t = group_feature(df, 'ship','t',['max','min','mean','std','skew','sum'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    t = group_feature(df, 'ship','d_d',['max','min','mean','std','skew','sum'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    t = group_feature(df, 'ship','d_t',['max','min','mean','std','skew','sum'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    t = group_feature(df, 'ship','d_x',['max','min','mean','std','skew','sum'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    t = group_feature(df, 'ship','v_x',['max','min','mean','std','skew','sum'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    t = group_feature(df, 'ship','d_y',['max','min','mean','std','skew','sum'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    t = group_feature(df, 'ship','v_y',['max','min','mean','std','skew','sum'])\n",
    "    train = pd.merge(train, t, on='ship', how='left')\n",
    "    ''' \n",
    "     \n",
    "    train['x_max_x_min'] = train['x_max'] - train['x_min']\n",
    "    train['y_max_y_min'] = train['y_max'] - train['y_min']\n",
    "    train['y_max_x_min'] = train['y_max'] - train['x_min']\n",
    "    train['x_max_y_min'] = train['x_max'] - train['y_min']\n",
    "    \n",
    "    train['slope_1'] = train['y_max_y_min'] / np.where(train['x_max_x_min']==0, 0.001, train['x_max_x_min']) #d_y / d_x\n",
    "    train['slope_2'] = train['y_sum'] / np.where(train['x_sum']==0, 0.001, train['x_sum'])\n",
    "    \n",
    "    train['area'] = train['x_max_x_min'] * train['y_max_y_min']\n",
    "    \n",
    "    #小时值的统计量，取value_counts最多的那个\n",
    "    mode_hour = df.groupby('ship')['hour'].agg(lambda x:x.value_counts().index[0]).to_dict()\n",
    "    train['mode_hour'] = train['ship'].map(mode_hour)\n",
    "\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_label = extract_feature(train, train_label)\n",
    "test_label = extract_feature(test, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相关性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 切片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_cut(train):\n",
    "    \n",
    "    bins = [0, 0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20]\n",
    "    labels = [0.5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20]\n",
    "    train['v_cut_1'] = pd.cut(train['v'],bins,labels = labels,include_lowest=True)\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = v_cut(train)\n",
    "test = v_cut(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 频数统计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_count(train):\n",
    "    \n",
    "    v_count = train['v_cut_1'].groupby([train['ship'], train['v_cut_1']]).count()\n",
    "    v_count = v_count.unstack()\n",
    "    v_count.columns = [v_count.columns.name+'_count_'+str(x) for x in v_count.columns.categories]\n",
    "    \n",
    "    v_count = v_count.fillna(0)\n",
    "    \n",
    "    return v_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.merge(train_label, v_count(train), on = 'ship')\n",
    "test_label = pd.merge(test_label, v_count(test), on = 'ship')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 切片相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vd_corr(train):\n",
    "    \n",
    "    vd_corr = train[['v','d']].groupby([train['ship'],train['v_cut_1']]).corr()\n",
    "    vd_corr_temp = vd_corr.unstack()\n",
    "    vd_corr_temp = vd_corr_temp['v']['d']\n",
    "    vd_corr = vd_corr_temp.unstack()\n",
    "    vd_corr.columns = [vd_corr.columns.name+'_corr_'+str(x) for x in vd_corr.columns.categories]\n",
    "    \n",
    "    vd_corr = vd_corr.fillna(-99)\n",
    "    \n",
    "    return vd_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.merge(train_label, vd_corr(train), on = 'ship')\n",
    "test_label = pd.merge(test_label, vd_corr(test), on = 'ship')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ship', 'type', 'x_max', 'x_min', 'x_mean', 'x_std', 'x_skew', 'x_sum',\n",
       "       'y_max', 'y_min', 'y_mean', 'y_std', 'y_skew', 'y_sum', 'v_max',\n",
       "       'v_min', 'v_mean', 'v_std', 'v_skew', 'v_sum', 'd_max', 'd_min',\n",
       "       'd_mean', 'd_std', 'd_skew', 'd_sum', 'x_max_x_min', 'y_max_y_min',\n",
       "       'y_max_x_min', 'x_max_y_min', 'slope_1', 'slope_2', 'area', 'mode_hour',\n",
       "       'v_cut_1_count_0.5', 'v_cut_1_count_1.0', 'v_cut_1_count_2.0',\n",
       "       'v_cut_1_count_3.0', 'v_cut_1_count_4.0', 'v_cut_1_count_5.0',\n",
       "       'v_cut_1_count_6.0', 'v_cut_1_count_7.0', 'v_cut_1_count_8.0',\n",
       "       'v_cut_1_count_9.0', 'v_cut_1_count_10.0', 'v_cut_1_count_20.0',\n",
       "       'v_cut_1_corr_0.5', 'v_cut_1_corr_1.0', 'v_cut_1_corr_2.0',\n",
       "       'v_cut_1_corr_3.0', 'v_cut_1_corr_4.0', 'v_cut_1_corr_5.0',\n",
       "       'v_cut_1_corr_6.0', 'v_cut_1_corr_7.0', 'v_cut_1_corr_8.0',\n",
       "       'v_cut_1_corr_9.0', 'v_cut_1_corr_10.0', 'v_cut_1_corr_20.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ship', 'x_max', 'x_min', 'x_mean', 'x_std', 'x_skew', 'x_sum', 'y_max',\n",
       "       'y_min', 'y_mean', 'y_std', 'y_skew', 'y_sum', 'v_max', 'v_min',\n",
       "       'v_mean', 'v_std', 'v_skew', 'v_sum', 'd_max', 'd_min', 'd_mean',\n",
       "       'd_std', 'd_skew', 'd_sum', 'x_max_x_min', 'y_max_y_min', 'y_max_x_min',\n",
       "       'x_max_y_min', 'slope_1', 'slope_2', 'area', 'mode_hour',\n",
       "       'v_cut_1_count_0.5', 'v_cut_1_count_1.0', 'v_cut_1_count_2.0',\n",
       "       'v_cut_1_count_3.0', 'v_cut_1_count_4.0', 'v_cut_1_count_5.0',\n",
       "       'v_cut_1_count_6.0', 'v_cut_1_count_7.0', 'v_cut_1_count_8.0',\n",
       "       'v_cut_1_count_9.0', 'v_cut_1_count_10.0', 'v_cut_1_count_20.0',\n",
       "       'v_cut_1_corr_0.5', 'v_cut_1_corr_1.0', 'v_cut_1_corr_2.0',\n",
       "       'v_cut_1_corr_3.0', 'v_cut_1_corr_4.0', 'v_cut_1_corr_5.0',\n",
       "       'v_cut_1_corr_6.0', 'v_cut_1_corr_7.0', 'v_cut_1_corr_8.0',\n",
       "       'v_cut_1_corr_9.0', 'v_cut_1_corr_10.0', 'v_cut_1_corr_20.0'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label.to_hdf('C:/Users/f3107/Desktop/hy_data/train_202.h5', 'df', mode='w')\n",
    "test_label.to_hdf('C:/Users/f3107/Desktop/hy_data/test_202.h5', 'df', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_label.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_label.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
